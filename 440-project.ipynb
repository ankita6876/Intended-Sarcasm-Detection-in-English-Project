{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#Imports\n\nimport pandas as pd\nimport numpy as np\nfrom transformers import AutoTokenizer\nfrom transformers import DataCollatorWithPadding\n!pip install evaluate\nimport evaluate\nfrom transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-03T20:05:29.711654Z","iopub.execute_input":"2023-09-03T20:05:29.712050Z","iopub.status.idle":"2023-09-03T20:05:42.604482Z","shell.execute_reply.started":"2023-09-03T20:05:29.712018Z","shell.execute_reply":"2023-09-03T20:05:42.603152Z"},"trusted":true},"execution_count":81,"outputs":[{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nRequirement already satisfied: evaluate in /opt/conda/lib/python3.10/site-packages (0.4.0)\nRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.1.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from evaluate) (1.23.5)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.7)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.0.2)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from evaluate) (4.66.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.3.0)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.15)\nRequirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2023.6.0)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.16.4)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from evaluate) (21.3)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.18.0)\nRequirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (11.0.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.8.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (3.12.2)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (6.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.6.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->evaluate) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2023.7.22)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.3)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.3)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.1.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.2)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.3)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"MODEL = \"bert-base-uncased\"\nBATCH_SIZE = 4\nEPOCHS = 10","metadata":{"execution":{"iopub.status.busy":"2023-09-03T20:05:42.607107Z","iopub.execute_input":"2023-09-03T20:05:42.611539Z","iopub.status.idle":"2023-09-03T20:05:42.619489Z","shell.execute_reply.started":"2023-09-03T20:05:42.611487Z","shell.execute_reply":"2023-09-03T20:05:42.618050Z"},"trusted":true},"execution_count":82,"outputs":[]},{"cell_type":"code","source":"#Loading in train data\n\ntrain = pd.read_csv(\"/kaggle/input/english-sarcasm-detection/train.En.csv\")\ntrain_C = pd.read_csv(\"/kaggle/input/english-sarcasm-detection/english_task_c.csv\")\ntrain_a = pd.read_csv(\"/kaggle/input/english-sarcasm-detection/english_task_a.csv\")\ntrain_B = pd.read_csv(\"/kaggle/input/english-sarcasm-detection/task_B_En_test.csv\")\n\ntest = pd.read_csv(\"/kaggle/input/english-sarcasm-detection/task_A_En_test.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-09-03T20:05:42.621938Z","iopub.execute_input":"2023-09-03T20:05:42.622400Z","iopub.status.idle":"2023-09-03T20:05:42.680817Z","shell.execute_reply.started":"2023-09-03T20:05:42.622361Z","shell.execute_reply":"2023-09-03T20:05:42.679454Z"},"trusted":true},"execution_count":83,"outputs":[]},{"cell_type":"code","source":"#Extracting parts of training data relevant for Task A\n\ntrain_A = train.loc[:, [\"tweet\", \"sarcastic\", \"rephrase\"]]\ntrain_C = train_C.loc[:, [\"text_1\", \"text_0\", \"human_aggregated\"]]\ntrain_a = train_a.loc[:, [\"text\", \"human_aggregated\"]]\ntrain_B = train_B.loc[:, [\"text\", \"sarcasm\", \"irony\", \"satire\", \"understatement\", \"overstatement\", \"rhetorical_question\"]]\n\ntest_A = test.loc[:, [\"text\", \"sarcastic\"]]","metadata":{"execution":{"iopub.status.busy":"2023-09-03T20:05:42.683526Z","iopub.execute_input":"2023-09-03T20:05:42.687673Z","iopub.status.idle":"2023-09-03T20:05:42.706082Z","shell.execute_reply.started":"2023-09-03T20:05:42.687625Z","shell.execute_reply":"2023-09-03T20:05:42.704698Z"},"trusted":true},"execution_count":84,"outputs":[]},{"cell_type":"code","source":"#Conveting train data to a format suitable for training\n\ntransformed_train_A = []\ntransformed_train_B = []\ntransformed_train_C = []\ntransformed_train_a = []\n\nfor i in range(len(train_A)):\n    transformed_train_A.append({\n        \"label\": train_A.iloc[i][\"sarcastic\"],\n        \"text\": train_A.iloc[i][\"tweet\"]\n    })\n    \n    transformed_train_A.append({\n        \"label\": 0,\n        \"text\": train_A.iloc[i][\"rephrase\"]\n    })\n\nfor i in range(len(train_B)):\n    if train_B.iloc[i][\"sarcasm\"] == 1 or train_B.iloc[i][\"irony\"] == 1 or train_B.iloc[i][\"satire\"] == 1 or train_B.iloc[i][\"understatement\"] == 1 or train_B.iloc[i][\"overstatement\"] == 1 or train_B.iloc[i][\"rhetorical_question\"] == 1:\n        transformed_train_B.append({\n        \"label\": 1,\n        \"text\": train_B.iloc[i][\"text\"]\n    })\n    else:\n        transformed_train_B.append({\n        \"label\": 0,\n        \"text\": train_B.iloc[i][\"text\"]\n    })\n    \nfor i in range(len(train_C)):\n    if train_C.iloc[i][\"human_aggregated\"] == 0:\n        transformed_train_C.append({\n            \"label\": 1,\n            \"text\": train_C.iloc[i][\"text_0\"]\n        })\n        \n        transformed_train_C.append({\n            \"label\": 0,\n            \"text\": train_C.iloc[i][\"text_1\"]\n        })\n    else:\n        transformed_train_C.append({\n            \"label\": 0,\n            \"text\": train_C.iloc[i][\"text_0\"]\n        })\n        \n        transformed_train_C.append({\n            \"label\": 1,\n            \"text\": train_C.iloc[i][\"text_1\"]\n        })\n    \nfor i in range(len(train_a)):\n    transformed_train_a.append({\n        \"label\": train_a.iloc[i][\"human_aggregated\"],\n        \"text\": train_a.iloc[i][\"text\"]\n    })\n    \ntransformed_test_A = []\n\nfor i in range(len(test_A)):\n    transformed_test_A.append({\n        \"label\": test_A.iloc[i][\"sarcastic\"],\n        \"text\": test_A.iloc[i][\"text\"]\n    })","metadata":{"execution":{"iopub.status.busy":"2023-09-03T20:05:42.711489Z","iopub.execute_input":"2023-09-03T20:05:42.714427Z","iopub.status.idle":"2023-09-03T20:05:44.660888Z","shell.execute_reply.started":"2023-09-03T20:05:42.714376Z","shell.execute_reply":"2023-09-03T20:05:44.659658Z"},"trusted":true},"execution_count":85,"outputs":[]},{"cell_type":"code","source":"#Tokenization\n\ntokenizer = AutoTokenizer.from_pretrained(MODEL)\n\ndef preprocess_function(text):\n    return tokenizer(text, truncation=True)\n\ntokenized_transformed_train_A = []\n\nfor dictionary in transformed_train_A:\n    if type(dictionary[\"text\"]) is type(\"string\"):\n        temp_dict = preprocess_function(dictionary[\"text\"])\n        temp_dict[\"label\"] = dictionary[\"label\"]\n        tokenized_transformed_train_A.append(temp_dict)\n        \ntokenized_transformed_train_C = []\n\nfor dictionary in transformed_train_C:\n    if type(dictionary[\"text\"]) is type(\"string\"):\n        temp_dict = preprocess_function(dictionary[\"text\"])\n        temp_dict[\"label\"] = dictionary[\"label\"]\n        tokenized_transformed_train_C.append(temp_dict)\n        \ntokenized_transformed_train_a = []\n\nfor dictionary in transformed_train_a:\n    if type(dictionary[\"text\"]) is type(\"string\"):\n        temp_dict = preprocess_function(dictionary[\"text\"])\n        temp_dict[\"label\"] = dictionary[\"label\"]\n        tokenized_transformed_train_a.append(temp_dict)\n        \ntokenized_transformed_train_B = []\n\nfor dictionary in transformed_train_B:\n    if type(dictionary[\"text\"]) is type(\"string\"):\n        temp_dict = preprocess_function(dictionary[\"text\"])\n        temp_dict[\"label\"] = dictionary[\"label\"]\n        tokenized_transformed_train_B.append(temp_dict)\n        \ntokenized_transformed_test_A = []\n\nfor dictionary in transformed_test_A:\n    if type(dictionary[\"text\"]) is type(\"string\"):\n        temp_dict = preprocess_function(dictionary[\"text\"])\n        temp_dict[\"label\"] = dictionary[\"label\"]\n        tokenized_transformed_test_A.append(temp_dict)","metadata":{"execution":{"iopub.status.busy":"2023-09-03T20:05:44.662741Z","iopub.execute_input":"2023-09-03T20:05:44.663478Z","iopub.status.idle":"2023-09-03T20:05:46.272087Z","shell.execute_reply.started":"2023-09-03T20:05:44.663439Z","shell.execute_reply":"2023-09-03T20:05:46.270828Z"},"trusted":true},"execution_count":86,"outputs":[]},{"cell_type":"code","source":"#Extending A dataset with community labelled C dataset\n\ntokenized_transformed_train_A.extend(tokenized_transformed_train_a)\ntokenized_transformed_train_A.extend(tokenized_transformed_train_C)","metadata":{"execution":{"iopub.status.busy":"2023-09-03T20:05:46.274147Z","iopub.execute_input":"2023-09-03T20:05:46.274966Z","iopub.status.idle":"2023-09-03T20:05:46.281798Z","shell.execute_reply.started":"2023-09-03T20:05:46.274921Z","shell.execute_reply":"2023-09-03T20:05:46.279795Z"},"trusted":true},"execution_count":87,"outputs":[]},{"cell_type":"code","source":"#Dynamic batchwise padding\n\ndata_collator = DataCollatorWithPadding(tokenizer=tokenizer)","metadata":{"execution":{"iopub.status.busy":"2023-09-03T20:05:46.285221Z","iopub.execute_input":"2023-09-03T20:05:46.286079Z","iopub.status.idle":"2023-09-03T20:05:46.311860Z","shell.execute_reply.started":"2023-09-03T20:05:46.286039Z","shell.execute_reply":"2023-09-03T20:05:46.310062Z"},"trusted":true},"execution_count":88,"outputs":[]},{"cell_type":"code","source":"#Evaluation metrics\n\naccuracy = evaluate.load(\"f1\")\n\ndef compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    predictions = np.argmax(predictions, axis=1)\n    return accuracy.compute(predictions=predictions, references=labels, pos_label=1, average = \"binary\")","metadata":{"execution":{"iopub.status.busy":"2023-09-03T20:05:46.314871Z","iopub.execute_input":"2023-09-03T20:05:46.315309Z","iopub.status.idle":"2023-09-03T20:05:47.448622Z","shell.execute_reply.started":"2023-09-03T20:05:46.315265Z","shell.execute_reply":"2023-09-03T20:05:47.447433Z"},"trusted":true},"execution_count":89,"outputs":[]},{"cell_type":"code","source":"#Id2label map and vice versa\n\nid2label = {0: \"non-sarcastic\", 1: \"sarcastic\"}\nlabel2id = {\"non-sarcastic\": 0, \"sarcastic\": 1}","metadata":{"execution":{"iopub.status.busy":"2023-09-03T20:05:47.452647Z","iopub.execute_input":"2023-09-03T20:05:47.453465Z","iopub.status.idle":"2023-09-03T20:05:47.461674Z","shell.execute_reply.started":"2023-09-03T20:05:47.453415Z","shell.execute_reply":"2023-09-03T20:05:47.460379Z"},"trusted":true},"execution_count":90,"outputs":[]},{"cell_type":"code","source":"#Defining the model\n\nmodel = AutoModelForSequenceClassification.from_pretrained(\n    MODEL, num_labels=2, id2label=id2label, label2id=label2id\n)","metadata":{"execution":{"iopub.status.busy":"2023-09-03T20:05:47.463748Z","iopub.execute_input":"2023-09-03T20:05:47.465368Z","iopub.status.idle":"2023-09-03T20:05:48.815086Z","shell.execute_reply.started":"2023-09-03T20:05:47.465306Z","shell.execute_reply":"2023-09-03T20:05:48.809334Z"},"trusted":true},"execution_count":91,"outputs":[{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"#Training and evaluation\n\ntraining_args = TrainingArguments(\n    output_dir=\"my_awesome_model\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=BATCH_SIZE,\n    per_device_eval_batch_size=BATCH_SIZE,\n    num_train_epochs=EPOCHS,\n    weight_decay=0.01,\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    load_best_model_at_end=True,\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_transformed_train_A,\n    eval_dataset=tokenized_transformed_test_A,\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n)\n\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2023-09-03T20:05:48.818400Z","iopub.execute_input":"2023-09-03T20:05:48.819087Z","iopub.status.idle":"2023-09-03T20:21:19.113428Z","shell.execute_reply.started":"2023-09-03T20:05:48.819042Z","shell.execute_reply":"2023-09-03T20:21:19.112252Z"},"trusted":true},"execution_count":92,"outputs":[{"name":"stderr","text":"You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='15340' max='15340' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [15340/15340 15:29, Epoch 10/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.538200</td>\n      <td>0.289030</td>\n      <td>0.590000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.520300</td>\n      <td>0.486802</td>\n      <td>0.621723</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.347300</td>\n      <td>0.587522</td>\n      <td>0.649903</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.209100</td>\n      <td>0.792615</td>\n      <td>0.645283</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.092500</td>\n      <td>0.924092</td>\n      <td>0.652908</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.071800</td>\n      <td>0.868732</td>\n      <td>0.635161</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.071400</td>\n      <td>1.098429</td>\n      <td>0.629981</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.038900</td>\n      <td>1.232798</td>\n      <td>0.635161</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.024100</td>\n      <td>1.264945</td>\n      <td>0.640301</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.014200</td>\n      <td>1.327932</td>\n      <td>0.637736</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":92,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=15340, training_loss=0.19346668064361133, metrics={'train_runtime': 929.1088, 'train_samples_per_second': 66.02, 'train_steps_per_second': 16.51, 'total_flos': 1310629138954920.0, 'train_loss': 0.19346668064361133, 'epoch': 10.0})"},"metadata":{}}]},{"cell_type":"code","source":"#f461aa864bc375133e0abc309bda5598d66d00a2","metadata":{"execution":{"iopub.status.busy":"2023-09-03T20:21:19.114896Z","iopub.execute_input":"2023-09-03T20:21:19.121315Z","iopub.status.idle":"2023-09-03T20:21:19.128370Z","shell.execute_reply.started":"2023-09-03T20:21:19.121272Z","shell.execute_reply":"2023-09-03T20:21:19.127365Z"},"trusted":true},"execution_count":93,"outputs":[]},{"cell_type":"code","source":"!rm -rf /kaggle/working/","metadata":{"execution":{"iopub.status.busy":"2023-09-03T20:21:19.129534Z","iopub.execute_input":"2023-09-03T20:21:19.130093Z","iopub.status.idle":"2023-09-03T20:21:21.188673Z","shell.execute_reply.started":"2023-09-03T20:21:19.130059Z","shell.execute_reply":"2023-09-03T20:21:21.187014Z"},"trusted":true},"execution_count":94,"outputs":[{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nrm: cannot remove '/kaggle/working/': Device or resource busy\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}